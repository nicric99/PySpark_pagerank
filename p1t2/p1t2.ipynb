{"cells":[{"cell_type":"code","execution_count":1,"id":"356f75c7","metadata":{},"outputs":[],"source":["import os\n","os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-xml_2.12:0.14.0 pyspark-shell'"]},{"cell_type":"code","execution_count":2,"id":"b53b016f","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":[":: loading settings :: url = jar:file:/usr/lib/spark/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"]},{"name":"stderr","output_type":"stream","text":["Ivy Default Cache set to: /root/.ivy2/cache\n","The jars for the packages stored in: /root/.ivy2/jars\n","com.databricks#spark-xml_2.12 added as a dependency\n",":: resolving dependencies :: org.apache.spark#spark-submit-parent-3756ebf2-eb3c-4e8e-903c-b935b6f99f0a;1.0\n","\tconfs: [default]\n","\tfound com.databricks#spark-xml_2.12;0.14.0 in central\n","\tfound commons-io#commons-io;2.8.0 in central\n","\tfound org.glassfish.jaxb#txw2;2.3.4 in central\n","\tfound org.apache.ws.xmlschema#xmlschema-core;2.2.5 in central\n",":: resolution report :: resolve 298ms :: artifacts dl 7ms\n","\t:: modules in use:\n","\tcom.databricks#spark-xml_2.12;0.14.0 from central in [default]\n","\tcommons-io#commons-io;2.8.0 from central in [default]\n","\torg.apache.ws.xmlschema#xmlschema-core;2.2.5 from central in [default]\n","\torg.glassfish.jaxb#txw2;2.3.4 from central in [default]\n","\t---------------------------------------------------------------------\n","\t|                  |            modules            ||   artifacts   |\n","\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n","\t---------------------------------------------------------------------\n","\t|      default     |   4   |   0   |   0   |   0   ||   4   |   0   |\n","\t---------------------------------------------------------------------\n",":: retrieving :: org.apache.spark#spark-submit-parent-3756ebf2-eb3c-4e8e-903c-b935b6f99f0a\n","\tconfs: [default]\n","\t0 artifacts copied, 4 already retrieved (0kB/9ms)\n","Setting default log level to \"WARN\".\n","To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n","22/05/01 14:55:01 INFO org.apache.spark.SparkEnv: Registering MapOutputTracker\n","22/05/01 14:55:01 INFO org.apache.spark.SparkEnv: Registering BlockManagerMaster\n","22/05/01 14:55:01 INFO org.apache.spark.SparkEnv: Registering BlockManagerMasterHeartbeat\n","22/05/01 14:55:01 INFO org.apache.spark.SparkEnv: Registering OutputCommitCoordinator\n","22/05/01 14:55:04 WARN org.apache.spark.deploy.yarn.Client: Same path resource file:///root/.ivy2/jars/com.databricks_spark-xml_2.12-0.14.0.jar added multiple times to distributed cache.\n","22/05/01 14:55:04 WARN org.apache.spark.deploy.yarn.Client: Same path resource file:///root/.ivy2/jars/commons-io_commons-io-2.8.0.jar added multiple times to distributed cache.\n","22/05/01 14:55:04 WARN org.apache.spark.deploy.yarn.Client: Same path resource file:///root/.ivy2/jars/org.glassfish.jaxb_txw2-2.3.4.jar added multiple times to distributed cache.\n","22/05/01 14:55:04 WARN org.apache.spark.deploy.yarn.Client: Same path resource file:///root/.ivy2/jars/org.apache.ws.xmlschema_xmlschema-core-2.2.5.jar added multiple times to distributed cache.\n","                                                                                \r"]}],"source":["from pyspark.sql import SparkSession\n","spark = SparkSession.builder.getOrCreate()\n","df = spark.read.format('xml').options(rowTag='page').load('hdfs:/enwiki_small.xml')"]},{"cell_type":"code","execution_count":3,"id":"c9d801bb","metadata":{},"outputs":[],"source":["from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col, udf , explode,lower, rtrim, regexp_replace\n","from pyspark.sql.types import StringType,ArrayType\n","import regex"]},{"cell_type":"code","execution_count":null,"id":"fb52aa5e","metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"ebbf3ae2","metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"8d173a11","metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":4,"id":"da25aee3","metadata":{},"outputs":[],"source":["v = df._jdf.schema().treeString()\n","text_file = open(\"schema.txt\", \"w\")\n","n = text_file.write(v)\n","text_file.close()"]},{"cell_type":"code","execution_count":5,"id":"5d034330","metadata":{},"outputs":[],"source":["from pyspark.sql.functions import col, udf , explode,lower, rtrim,regexp_replace\n","from pyspark.sql.types import StringType,ArrayType\n","import regex"]},{"cell_type":"markdown","id":"d0917975","metadata":{},"source":["# task2 \n"]},{"cell_type":"code","execution_count":6,"id":"7848d1c1","metadata":{},"outputs":[{"data":{"text/plain":["2"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["1+1"]},{"cell_type":"markdown","id":"a765eb3a","metadata":{},"source":["### The Instructions are unclear the way it is preferred. So if we assume the counts are"]},{"cell_type":"code","execution_count":9,"id":"b108efc0","metadata":{},"outputs":[],"source":["def return_links(text):\n","    innerlink = regex.findall(r'\\[\\[((?:[^[\\]]+|(?R))*+)\\]\\]', text)\n","    if innerlink:\n","        return innerlink\n","    return None\n","return_links_udf = udf(lambda text: return_links(text), ArrayType(StringType()))\n","new_df = df.select(col('title'), col('revision.text._VALUE').alias('text'))\n","new_df = new_df.withColumn('article', explode(return_links_udf(lower(col('text')))))\n","new_df = new_df.withColumn('article', regexp_replace(col('article'),\".*\\#[^\\|]+\\|?\",\"\"))\n","new_df = new_df.withColumn('article', regexp_replace(col('article'),\".*(?!Category)\\:[^\\|]+\\|?\",\"\"))\n","new_df = new_df.withColumn('article', regexp_replace(col('article'),\"\\|.*\",\"\"))\n","new_df = new_df.filter(\"article != ''\")"]},{"cell_type":"code","execution_count":null,"id":"7c28b596","metadata":{},"outputs":[],"source":["# This is slower process "]},{"cell_type":"code","execution_count":8,"id":"20c16c8f","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"data":{"text/plain":["4342885"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["new_df.count()"]},{"cell_type":"code","execution_count":13,"id":"da3e973c","metadata":{},"outputs":[],"source":["\n","def return_links(text):\n","    try:\n","        results = regex.findall(r'\\[\\[((?:[^[\\]]+|(?R))*+)\\]\\]', text)\n","    except:\n","        return []\n","    output = []\n","    for res in results:\n","        for link in res.split('|'):\n","            if '#' in link:\n","                continue\n","            elif ':' in link and 'Category:' not in link:\n","                continue\n","            else:\n","                output.append(link.lower())\n","                break\n","    return output\n","\n","\n","link_udf = udf(lambda text: return_links(text), ArrayType(StringType()))\n","new_df = df.withColumn(\"article\", explode(link_udf(col(\"revision.text._VALUE\"))))\n","new_df = new_df.select(lower(col('title')).alias('title'), 'article').orderBy('title', 'article')"]},{"cell_type":"code","execution_count":14,"id":"7af8d681","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"data":{"text/plain":["4413998"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["new_df.count()"]},{"cell_type":"code","execution_count":13,"id":"3b7e4ef8","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["+-------------------+--------------------+\n","|              title|             article|\n","+-------------------+--------------------+\n","|accessiblecomputing|computer accessib...|\n","|          anarchism|political philosophy|\n","|          anarchism|      state (polity)|\n","|          anarchism|   stateless society|\n","|          anarchism|             anarchy|\n","|          anarchism|  the globe and mail|\n","|          anarchism|routledge encyclo...|\n","|          anarchism|           authority|\n","|          anarchism|the oxford compan...|\n","|          anarchism|  family resemblance|\n","|          anarchism|the oxford compan...|\n","|          anarchism|oxford university...|\n","|          anarchism|  mutually exclusive|\n","|          anarchism|    social anarchism|\n","|          anarchism|individualist ana...|\n","|          anarchism| geoffrey ostergaard|\n","|          anarchism|           left-wing|\n","|          anarchism|  the new york times|\n","|          anarchism| anarchist economics|\n","|          anarchism|       anarchist law|\n","+-------------------+--------------------+\n","only showing top 20 rows\n","\n"]}],"source":["new_df.show()"]},{"cell_type":"code","execution_count":null,"id":"33148331","metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":17,"id":"f84b1158","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["new_df.limit(5).toPandas().to_csv('/home/saisur/part2.csv', sep='\\t', index=False)"]},{"cell_type":"code","execution_count":17,"id":"677fb2c5","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["new_df.repartition(10).write.option(\"delimiter\", \"\\t\").csv('part2_small')"]},{"cell_type":"code","execution_count":null,"id":"0fa40873","metadata":{},"outputs":[],"source":["## Python Code final for not splitting\n","from pyspark.sql.functions import col, udf , explode,lower, rtrim, regexp_replace\n","from pyspark.sql.types import StringType,ArrayType\n","import regex\n","\n","# Get the spark instance and get the file \n","spark = SparkSession.builder.getOrCreate()\n","df = spark.read.format('xml').options(rowTag='page').load('hdfs:/enwiki_test.xml')\n","\n","# Get the find all  of particular type \n","def return_links(text):\n","    innerlink = regex.findall(r'\\[\\[((?:[^[\\]]+|(?R))*+)\\]\\]', text)\n","    if innerlink:\n","        return innerlink\n","    return None\n","\n","\n","return_links_udf = udf(lambda text: return_links(text), ArrayType(StringType()))\n","new_df = df.select(col('title'), col('revision.text._VALUE').alias('text'))\n","new_df = new_df.withColumn('article', explode(return_links_udf(lower(col('text')))))\n","new_df = new_df.withColumn('article', regexp_replace(col('article'),\".*\\#[^\\|]+\\|?\",\"\"))\n","new_df = new_df.withColumn('article', regexp_replace(col('article'),\".*(?!Category)\\:[^\\|]+\\|?\",\"\"))\n","new_df = new_df.withColumn('article', regexp_replace(col('article'),\"\\|.*\",\"\"))\n","new_df = new_df.filter(\"article != ''\")\n","new_df = new_df.select(lower(col('title')).alias('title'), 'article')\n","new_df.repartition(10).write.option(\"delimiter\", \"\\t\").csv('part2_small')\n","\n","\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"}},"nbformat":4,"nbformat_minor":5}